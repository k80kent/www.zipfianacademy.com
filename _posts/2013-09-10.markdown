---
categories: data_science
date: 2013/09/10 00:00:00
title: The data science mindset
---
Data science involves using lots of hip tools with sexy names like "R",
but data science isnâ€™t all about the tools you use. I see it as a mindset,
a way of looking at the world. It's about taking advantage of our modern
computers and all of the information (data) that they're already collecting
in order to study how things work. If we start this mindset, a lot of
data science approaches naturally follow.

## Store everything
Storage is cheap, so you should store everything that is easy to collect;
You don't need a full-fleged research plan before you start collecting data.
Store it in the most raw form that is convenient, and don't worry very
much about how or even whether you're going to analyze it.

### Use existing data
Since we're already storing data, let's use it.
When I have a question about the world, I adapt the question so that it can
be approximately answered with an existing and convenient dataset. I look for
opportunities to use existing stores of data in unintended ways.

### Connect datasets
Since you're storing everything, you should focus on connecting datasets rather than on tuning models.
In a conventional statistics class, you'll learn a lot about how to choose
analysis methods that are appropriate for your data collection approach and how
to tune the models for a specific dataset.

Now that we suddenly have hoards of inexpensive data that we haven't seen before,
there's a lot to be learned by using more of these data. Don't worry so much
about making the best use out of one dataset; data science is about using a range of
datasets, and especially about connect one dataset to lots of other datasets. To use
machine learning speak, you should focus more on collecting features rather than on
tuning your model.

## Anything can be quantified
Everything can be turned into a number, and these numbers can be put in tables.
By quantifying things, we simplify them such that a computer can process them.

A [spreadsheet about sewer overflows](https://data.illinois.gov/Municipality/SSMMA-Combined-Sewer-Overflow/5yuf-j7kn?)
is clearly data to most people, but what about a [calendar](http://www.mo.gov/meetings/)?
At first, a calendar
might not seem like the sort of data that you analyze with statistics, but you
can represent a calendar as a [spreadsheet](https://data.mo.gov/Government-Administration/Open-Meetings/au6r-w9n3)
and [as a graph](http://thomaslevine.com/!/socrata-calendars).

![](http://thomaslevine.com/!/socrata-calendars/figure/day-of-week.png)

Part of data science is not being restricted to the obvious variables that are presented to you.
Maybe you have a bunch of PDF documents. You could extract the text and search through that, but
that's not the only data you have; without looking at the text at all, you can get the page count,
the size of the file, the shapes of the pages and the [program that created it](http://thomaslevine.com/!/parsing-pdfs/).

To me, there is no big difference between "qualitative" and "quantitative" data
nor between "unstructured" and "structured" data because I know that I can convert
between these opposites.

For example, Company registration papers might not seem like data. They start as paper,
most of their fields are text, and their formats aren't particularly standard.
But when you put them in [one database](http://opencorporates.com/) in a standard format,
things start to [feel like data](http://registries.opencorporates.com/).

## Boring work should be sent to robots
If something must be done and nobody wants to do it, we should get a robot to
do it. Within the context of data analysis, a typical boring task might be drawing a new graph every time some
dataset is updated. A robot will do this with substantially more
consistency/accuracy and for a substantially lower cost.

Data collection is one sort task that should often be sent to a robot. Questionnaires
and lab studies are too much work for the researcher and the participants;
it's more data sciencey to collect the data automatically and unobtrusively,
like by logging the clicks that you're already making on a website.

Robots can also remember what you did so that you don't have to; rather than learning
and remembering your whole analysis process, you can write a program that does the whole
thing for you, from the original acquisition of the data to the modelling to the presentation
of results to a human. By making everything a program, you make it easier to
find mistakes, to update your analyses, and to turn an analysis into a product.

## Tools
Since I have the aforementioned mindset and the consequential mindsets, I wind
up learning a bunch of tools that align with that mindset. For example, I know
how to collect lots of data continuously, how to store it, how to get it out of
storage, how to have a computer fit models and make predictions on datasets that I can't fit in my head,
how to convert paper documents into data tables, how to get the computer to tell
me something that I and other people will understand, and how to make all of this run
fast enough that I don't get tired of waiting.

Properly discussing these relevant tools would take a while, but here's a small
thought: You don't need to know much math to do data science. Loads of wonderful
algorithms have already been implemented for you, and simple algorithms work quite
well. The more important tools are "plumbing" that connects different datasets and systems.

Rather than grouping our 12-week course into different software packages or algorithms
that you might want to use, we're grouping the course by typical projects that you
might want to conduct. For example, the first week is a recommender. In doing each
project, students will use a range of different programs, datasets and methods, and
they'll build the plumbing that connects these different components.
