---
categories: data_science
date: 2013/09/01 00:00:00
title: The data science mindset
---
I resisted defining "data science" for the longest time, but I recently figured
I should define it because otherwise I'd have no idea what to teach. :)

I don't see "data science" as being about specific tools or datasets
or math; rather, it's the mindset that we can exploit inexpensive computing
power to study how the world works. If you start with this mindset, the
various contemporary data science techniques follow.

People started calling me a "data scientist" without telling me what it meant,
so this mindset is really just my mindset, and I figure that people who think
like I do are data scientists.

## Store everything
Storage is cheap, so you should store everything that is easy to collect.
Store it in the most raw form that is convenient, and don't worry very
much about how or even whether you're going to analyze it.

### Use existing data
When I'm asked a question about the world, I adapt the question so that it can
be approximately answered with an existing and convenient dataset. I look for
opportunities to use existing stores of data in unintended ways.

### Connect datasets
Since you're storing everything, you should focus on connecting datasets rather than on tuning models.
In a conventional statistics class, you'll learn a lot about how to choose
analysis methods that are appropriate for your data collection approach and how
to tune the models for a specific dataset.

Now that we suddenly have hoards of inexpensive data that we haven't seen before,
there's a lot to be learned by looking using more of these data. Don't worry so much
about making the best use out of one dataset; data science is about using a range of
datasets, and especially about connect one dataset to lots of other datasets. To use
machine learning speak, you should focus more on collecting features rather than on
tuning your model.

## Anything can be quantified
Everything can be turned into a number, and these numbers can be put in tables.
By quantifying things, we simplify them such that a computer can process them.

To me, there is no big difference between "qualitative" and "quantitative" data
nor between "unstructured" and "structured" data because I know that I can convert
between these opposites.

Read more about this [here](http://thomaslevine.com/!/world-data-world).

## Boring work should be sent to robots
In general, I think that people should only do things that they want to do;
if something must be done and nobody wants to do it, a robot should do it[^robot]
I could come up with economic arguments for this, but this is almost an ethical view for me.

Within the context of data analysis, there are some much more practical reasons
for this. A typical boring task might be drawing a new graph every time some
dataset is updated. A robot will do this with substantially more
consistency/accuracy and for a substantially lower cost. Here are some of my
attitudes that relate to this concept.

* Data collection should be automatic and unobtrusive; questionnaires and lab
    studies are too much work.
* I don't need a full-fleged research plan before you start collecting data;
    I'll record everything that is convenient, and I'll store it in the most raw form.
* All analyses should be scripted.

To say this more explosively, I value laziness.

## Tools
Since I have the aforementioned mindset and the consequential mindsets, I wind
up learning a bunch of tools that align with that mindset. For example, I know
how to collect lots of data continuously, how to store it, how to get it out of
storage, how to have a computer analyze datasets that I can't fit in my head,
how to convert paper documents into data tables, how to get the computer to tell
me something that I and other people understand, and how to make all of this run
fast enough that I don't get tired of waiting.

Properly discussing these relevant tools would take a while, but here's a small
thought: You don't need to know much math to do data science. Loads of wonderful
algorithms have already been implemented for you, and simple algorithms work quite
well. The more important tools are "plumbing" that connects different datasets and systems.

Rather than grouping our 12-week course into different software packages or algorithms
that you might want to do, we're grouping the course by typical projects that you
might want to conduct. For example, the first week is a recommender. In doing each
project, students will use a range of different programs, datasets and methods, and
they'll build the plumbing that connects these different components.
